{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff49c0cc-6761-4996-b9e0-15228dc96bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence to predict (or leave blank to use a CSV):  \n",
      "Enter path to input CSV (or press Enter to cancel):  C:\\Users\\sagni\\Downloads\\archive\\sustainable_fashion_trends_2024.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVE] Predictions -> C:\\Users\\sagni\\Downloads\\Eco Habit\\predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# === predict_ecohabit.py (Jupyter-safe with interactive fallback) ===\n",
    "# Loads artifacts from: C:\\Users\\sagni\\Downloads\\Eco Habit\n",
    "# Predict on: --text \"...\"  OR  --in <csv>\n",
    "# If no args, prompts interactively.\n",
    "\n",
    "import os, sys, argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "OUT_DIR   = r\"C:\\Users\\sagni\\Downloads\\Eco Habit\"\n",
    "PKL_PATH  = os.path.join(OUT_DIR, \"mindpal_preprocess.pkl\")\n",
    "H5_PATH   = os.path.join(OUT_DIR, \"mindpal_model.h5\")\n",
    "DEFAULT_OUT = os.path.join(OUT_DIR, \"predictions.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# Helper classes (for joblib unpickle)\n",
    "# -----------------------------\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column): self.column = column\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X): return X[[self.column]]\n",
    "\n",
    "class To1DString(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return X.iloc[:, 0].astype(str).values\n",
    "        return np.asarray(X).astype(str).ravel()\n",
    "\n",
    "class DateTimeExpand(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns): self.columns = columns\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        outs = []\n",
    "        for c in self.columns:\n",
    "            s = pd.to_datetime(X[c], errors=\"coerce\")\n",
    "            outs.append(pd.DataFrame({\n",
    "                f\"{c}_year\":  s.dt.year.fillna(0).astype(int),\n",
    "                f\"{c}_month\": s.dt.month.fillna(0).astype(int),\n",
    "                f\"{c}_day\":   s.dt.day.fillna(0).astype(int),\n",
    "                f\"{c}_dow\":   s.dt.dayofweek.fillna(0).astype(int),\n",
    "            }))\n",
    "        return pd.concat(outs, axis=1) if outs else np.empty((len(X), 0))\n",
    "\n",
    "# -----------------------------\n",
    "# Utils\n",
    "# -----------------------------\n",
    "def ensure_dense_if_small(X, max_feats=50000):\n",
    "    if hasattr(X, \"toarray\") and X.shape[1] <= max_feats:\n",
    "        return X.toarray()\n",
    "    return X\n",
    "\n",
    "def compile_loaded_model(model, n_classes: int):\n",
    "    # Compiling silences the absl warning; not required for predict(), but helpful.\n",
    "    if n_classes <= 2:\n",
    "        model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    else:\n",
    "        model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "def build_df_for_text(text: str, bundle: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a 1-row DataFrame matching training schema:\n",
    "    - puts `text` into the first text column seen during training\n",
    "    - fills numeric with 0, categorical with 'unknown', datetime with today\n",
    "    \"\"\"\n",
    "    cols_num  = bundle.get(\"numeric_cols\", [])\n",
    "    cols_cat  = bundle.get(\"cat_cols\", [])\n",
    "    cols_txt  = bundle.get(\"text_cols\", [])\n",
    "    cols_dt   = bundle.get(\"datetime_cols\", [])\n",
    "    data = {}\n",
    "    for c in cols_num: data[c] = [0]\n",
    "    for c in cols_cat: data[c] = [\"unknown\"]\n",
    "    for c in cols_dt:  data[c] = [pd.Timestamp.today()]\n",
    "    if cols_txt:\n",
    "        for i, c in enumerate(cols_txt):\n",
    "            data[c] = [text] if i == 0 else [\"\"]\n",
    "    else:\n",
    "        # Fallback if no text columns were detected during training\n",
    "        data[\"text\"] = [text]\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def predict_dataframe(df_in: pd.DataFrame, bundle: dict, model, out_csv=None, print_out=False) -> pd.DataFrame:\n",
    "    preprocess    = bundle[\"preprocess\"]\n",
    "    label_encoder = bundle[\"label_encoder\"]\n",
    "    X_proc = preprocess.transform(df_in)\n",
    "    X_proc = ensure_dense_if_small(X_proc)\n",
    "\n",
    "    probs = model.predict(X_proc, verbose=0)\n",
    "    classes = [str(c) for c in label_encoder.classes_]\n",
    "    n_classes = len(classes)\n",
    "\n",
    "    if probs.ndim == 1 or probs.shape[1] == 1:\n",
    "        # Binary: make 2-col prob matrix [neg, pos]\n",
    "        pos = probs.ravel()\n",
    "        neg = 1.0 - pos\n",
    "        prob_mat = np.vstack([neg, pos]).T\n",
    "        pred_idx = (pos >= 0.5).astype(int)\n",
    "    else:\n",
    "        prob_mat = probs\n",
    "        pred_idx = np.argmax(prob_mat, axis=1)\n",
    "\n",
    "    pred_labels = label_encoder.inverse_transform(pred_idx)\n",
    "    out = df_in.copy()\n",
    "    out.insert(0, \"pred_label\", pred_labels)\n",
    "    # attach probabilities\n",
    "    if n_classes <= 2 and prob_mat.shape[1] == 2:\n",
    "        # keep only positive class prob if you prefer: out[\"prob\"] = prob_mat[:, 1]\n",
    "        # or add both:\n",
    "        out[\"prob_neg\"] = prob_mat[:, 0]\n",
    "        out[\"prob_pos\"] = prob_mat[:, 1]\n",
    "    else:\n",
    "        for j, cls in enumerate(classes):\n",
    "            out[f\"prob_{cls}\"] = prob_mat[:, j]\n",
    "\n",
    "    if out_csv:\n",
    "        out.to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "        print(f\"[SAVE] Predictions -> {out_csv}\")\n",
    "\n",
    "    if print_out:\n",
    "        cols = [\"pred_label\"] + [c for c in out.columns if c.startswith(\"prob_\")]\n",
    "        print(out[cols].head(20).to_string(index=False))\n",
    "\n",
    "    return out\n",
    "\n",
    "# -----------------------------\n",
    "# CLI\n",
    "# -----------------------------\n",
    "def parse_args(argv=None):\n",
    "    p = argparse.ArgumentParser(description=\"EcoHabit predictor\")\n",
    "    p.add_argument(\"--in\",   dest=\"in_csv\",   type=str, default=None, help=\"Input CSV (same columns as training)\")\n",
    "    p.add_argument(\"--out\",  dest=\"out_csv\",  type=str, default=None, help=\"Output predictions CSV path\")\n",
    "    p.add_argument(\"--text\", dest=\"single_text\", type=str, default=None, help=\"Single text to predict\")\n",
    "    p.add_argument(\"--print\", dest=\"do_print\", action=\"store_true\", help=\"Print predictions to console\")\n",
    "    return p.parse_args(argv)\n",
    "\n",
    "def main(argv=None):\n",
    "    # If running inside Jupyter, strip its injected args.\n",
    "    if argv is None and (\"ipykernel_launcher\" in sys.argv[0] or any(a == \"-f\" for a in sys.argv)):\n",
    "        argv = []\n",
    "\n",
    "    args = parse_args(argv)\n",
    "\n",
    "    # Interactive fallback if no args given\n",
    "    if args.single_text is None and args.in_csv is None:\n",
    "        try:\n",
    "            s = input(\"Enter a sentence to predict (or leave blank to use a CSV): \").strip()\n",
    "        except EOFError:\n",
    "            s = \"\"\n",
    "        if s:\n",
    "            args.single_text = s\n",
    "        else:\n",
    "            csv_path = input(\"Enter path to input CSV (or press Enter to cancel): \").strip()\n",
    "            if not csv_path:\n",
    "                raise ValueError(\"Provide either --text 'some sentence' or --in path\\\\to\\\\file.csv\")\n",
    "            args.in_csv = csv_path\n",
    "\n",
    "    # Load artifacts\n",
    "    if not os.path.exists(PKL_PATH):\n",
    "        raise FileNotFoundError(f\"Missing preprocess bundle: {PKL_PATH}\")\n",
    "    if not os.path.exists(H5_PATH):\n",
    "        raise FileNotFoundError(f\"Missing model file: {H5_PATH}\")\n",
    "\n",
    "    bundle = joblib.load(PKL_PATH)\n",
    "    model  = load_model(H5_PATH)\n",
    "    compile_loaded_model(model, len(bundle[\"label_encoder\"].classes_))\n",
    "\n",
    "    # Build input\n",
    "    if args.single_text is not None:\n",
    "        df_in = build_df_for_text(args.single_text, bundle)\n",
    "    else:\n",
    "        if not os.path.exists(args.in_csv):\n",
    "            raise FileNotFoundError(f\"Input CSV not found: {args.in_csv}\")\n",
    "        df_in = pd.read_csv(args.in_csv)\n",
    "\n",
    "    out_csv = args.out_csv or DEFAULT_OUT\n",
    "    predict_dataframe(df_in, bundle, model, out_csv=out_csv, print_out=args.do_print)\n",
    "\n",
    "# -----------------------------\n",
    "# Optional: importable helpers for notebooks\n",
    "# -----------------------------\n",
    "def predict_text(text: str, save_to: str = None, show=True):\n",
    "    \"\"\"Notebook helper: predict directly from a text string.\"\"\"\n",
    "    bundle = joblib.load(PKL_PATH)\n",
    "    model  = load_model(H5_PATH)\n",
    "    compile_loaded_model(model, len(bundle[\"label_encoder\"].classes_))\n",
    "    df_in = build_df_for_text(text, bundle)\n",
    "    return predict_dataframe(df_in, bundle, model, out_csv=save_to, print_out=show)\n",
    "\n",
    "def predict_csv(csv_path: str, save_to: str = None, show=True):\n",
    "    \"\"\"Notebook helper: predict directly from a CSV file.\"\"\"\n",
    "    bundle = joblib.load(PKL_PATH)\n",
    "    model  = load_model(H5_PATH)\n",
    "    compile_loaded_model(model, len(bundle[\"label_encoder\"].classes_))\n",
    "    df_in = pd.read_csv(csv_path)\n",
    "    return predict_dataframe(df_in, bundle, model, out_csv=save_to, print_out=show)\n",
    "\n",
    "# -----------------------------\n",
    "# Entrypoint\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c790e-0251-4726-856f-19357cc3a430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
