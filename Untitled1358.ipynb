{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b70cbb71-bd6e-4945-b635-abc9871aef26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Saved plots & reports to: C:\\Users\\sagni\\Downloads\\Eco Habit ===\n",
      " - accuracy.png (if history was present)\n",
      " - loss.png (if history was present)\n",
      " - confusion_matrix.png\n",
      " - confusion_matrix_norm.png\n",
      " - predictions.csv\n",
      " - classification_report.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "OUT_DIR   = r\"C:\\Users\\sagni\\Downloads\\Eco Habit\"\n",
    "DATA_PATH = r\"C:\\Users\\sagni\\Downloads\\archive\\sustainable_fashion_trends_2024.csv\"\n",
    "\n",
    "PKL_PATH  = os.path.join(OUT_DIR, \"mindpal_preprocess.pkl\")\n",
    "H5_PATH   = os.path.join(OUT_DIR, \"mindpal_model.h5\")\n",
    "HIST_CSV  = os.path.join(OUT_DIR, \"training_history.csv\")\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Define the SAME helper classes used during training\n",
    "# (needed so joblib can unpickle the pipeline)\n",
    "# -------------------------------------------------\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column): self.column = column\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X): return X[[self.column]]\n",
    "\n",
    "class To1DString(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return X.iloc[:, 0].astype(str).values\n",
    "        return np.asarray(X).astype(str).ravel()\n",
    "\n",
    "class DateTimeExpand(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns): self.columns = columns; self.out_cols = []\n",
    "    def fit(self, X, y=None):\n",
    "        self.out_cols = []\n",
    "        for c in self.columns:\n",
    "            self.out_cols += [f\"{c}_year\", f\"{c}_month\", f\"{c}_day\", f\"{c}_dow\"]\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        outs = []\n",
    "        for c in self.columns:\n",
    "            s = pd.to_datetime(X[c], errors=\"coerce\")\n",
    "            outs.append(pd.DataFrame({\n",
    "                f\"{c}_year\":  s.dt.year.fillna(0).astype(int),\n",
    "                f\"{c}_month\": s.dt.month.fillna(0).astype(int),\n",
    "                f\"{c}_day\":   s.dt.day.fillna(0).astype(int),\n",
    "                f\"{c}_dow\":   s.dt.dayofweek.fillna(0).astype(int),\n",
    "            }))\n",
    "        return pd.concat(outs, axis=1) if outs else np.empty((len(X), 0))\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def ensure_dense_if_small(X, max_feats=50000):\n",
    "    if hasattr(X, \"toarray\") and X.shape[1] <= max_feats:\n",
    "        return X.toarray()\n",
    "    return X\n",
    "\n",
    "def compile_loaded_model(model, n_classes: int):\n",
    "    if n_classes <= 2:\n",
    "        model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    else:\n",
    "        model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Plot Accuracy & Loss from history CSV (if available)\n",
    "# -----------------------------\n",
    "if os.path.exists(HIST_CSV):\n",
    "    hist_df = pd.read_csv(HIST_CSV)\n",
    "\n",
    "    def plot_curve(x, y1, y2, title, ylabel, out_path):\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.plot(x, y1, label=\"Train\")\n",
    "        if y2 is not None:\n",
    "            plt.plot(x, y2, label=\"Validation\")\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_path, dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "    epochs = hist_df[\"epoch\"] if \"epoch\" in hist_df.columns else np.arange(1, len(hist_df)+1)\n",
    "\n",
    "    # Accuracy\n",
    "    acc_col = \"accuracy\" if \"accuracy\" in hist_df.columns else (\"acc\" if \"acc\" in hist_df.columns else None)\n",
    "    val_acc_col = \"val_accuracy\" if \"val_accuracy\" in hist_df.columns else (\"val_acc\" if \"val_acc\" in hist_df.columns else None)\n",
    "    if acc_col:\n",
    "        plot_curve(\n",
    "            epochs,\n",
    "            hist_df[acc_col],\n",
    "            hist_df[val_acc_col] if val_acc_col and val_acc_col in hist_df.columns else None,\n",
    "            \"Model Accuracy\",\n",
    "            \"Accuracy\",\n",
    "            os.path.join(OUT_DIR, \"accuracy.png\")\n",
    "        )\n",
    "\n",
    "    # Loss\n",
    "    val_loss_series = hist_df[\"val_loss\"] if \"val_loss\" in hist_df.columns else None\n",
    "    plot_curve(\n",
    "        epochs,\n",
    "        hist_df[\"loss\"],\n",
    "        val_loss_series,\n",
    "        \"Model Loss\",\n",
    "        \"Loss\",\n",
    "        os.path.join(OUT_DIR, \"loss.png\")\n",
    "    )\n",
    "else:\n",
    "    print(\"[WARN] training_history.csv not found â€” skipping accuracy/loss curves.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Recreate test split, predict, and plot confusion matrices\n",
    "# -----------------------------\n",
    "missing = [p for p in [PKL_PATH, H5_PATH, DATA_PATH] if not os.path.exists(p)]\n",
    "if missing:\n",
    "    raise FileNotFoundError(f\"Missing required files: {missing}\")\n",
    "\n",
    "# Load bundle & model\n",
    "bundle = joblib.load(PKL_PATH)\n",
    "model  = load_model(H5_PATH)\n",
    "\n",
    "# Compile to silence absl warning and ensure metrics available\n",
    "n_classes = len(bundle[\"label_encoder\"].classes_)\n",
    "compile_loaded_model(model, n_classes)\n",
    "\n",
    "# Rebuild the test set exactly like training\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "target_col = bundle[\"target_col\"]\n",
    "if target_col not in df.columns:\n",
    "    raise ValueError(f\"Target column '{target_col}' not found in data file.\")\n",
    "\n",
    "X = df.drop(columns=[target_col])\n",
    "y = bundle[\"label_encoder\"].transform(df[target_col].astype(str))\n",
    "\n",
    "X_train_df, X_test_df, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y if n_classes > 1 else None\n",
    ")\n",
    "\n",
    "preprocess = bundle[\"preprocess\"]\n",
    "X_test_t = preprocess.transform(X_test_df)\n",
    "X_test_t = ensure_dense_if_small(X_test_t)\n",
    "\n",
    "probs = model.predict(X_test_t, verbose=0)\n",
    "if n_classes <= 2:\n",
    "    y_pred = (probs.ravel() >= 0.5).astype(int)\n",
    "else:\n",
    "    y_pred = np.argmax(probs, axis=1)\n",
    "\n",
    "# Save predictions CSV and classification report\n",
    "pred_csv = os.path.join(OUT_DIR, \"predictions.csv\")\n",
    "pred_df = pd.DataFrame({\n",
    "    \"true_label\": bundle[\"label_encoder\"].inverse_transform(y_test),\n",
    "    \"pred_label\": bundle[\"label_encoder\"].inverse_transform(y_pred)\n",
    "})\n",
    "pred_df.to_csv(pred_csv, index=False, encoding=\"utf-8\")\n",
    "\n",
    "report_txt = os.path.join(OUT_DIR, \"classification_report.txt\")\n",
    "with open(report_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(classification_report(y_test, y_pred, target_names=[str(c) for c in bundle[\"label_encoder\"].classes_]))\n",
    "\n",
    "# Confusion matrices\n",
    "labels = [str(c) for c in bundle[\"label_encoder\"].classes_]\n",
    "cm = confusion_matrix(y_test, y_pred, labels=np.arange(len(labels)))\n",
    "cm_norm = cm.astype(float) / (cm.sum(axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "def plot_cm(cm_mat, labels, title, out_path, normalize=False):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    im = plt.imshow(cm_mat, interpolation=\"nearest\", aspect=\"auto\")\n",
    "    plt.title(title)\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45, ha=\"right\")\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    thresh = cm_mat.max() / 2.0 if cm_mat.size else 0.5\n",
    "    for i in range(cm_mat.shape[0]):\n",
    "        for j in range(cm_mat.shape[1]):\n",
    "            val = cm_mat[i, j]\n",
    "            txt = f\"{val:.2f}\" if normalize else f\"{int(val)}\"\n",
    "            plt.text(j, i, txt, ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if val > thresh else \"black\", fontsize=9)\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "plot_cm(cm, labels, \"Confusion Matrix (Counts)\", os.path.join(OUT_DIR, \"confusion_matrix.png\"), normalize=False)\n",
    "plot_cm(cm_norm, labels, \"Confusion Matrix (Row-Normalized)\", os.path.join(OUT_DIR, \"confusion_matrix_norm.png\"), normalize=True)\n",
    "\n",
    "print(\"\\n=== Saved plots & reports to:\", OUT_DIR, \"===\")\n",
    "print(\" - accuracy.png (if history was present)\")\n",
    "print(\" - loss.png (if history was present)\")\n",
    "print(\" - confusion_matrix.png\")\n",
    "print(\" - confusion_matrix_norm.png\")\n",
    "print(\" - predictions.csv\")\n",
    "print(\" - classification_report.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ac43cc-55cf-42e6-8ea4-8c6880b2df27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
