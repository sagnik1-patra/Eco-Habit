{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d5f3ac-9c36-46d4-a495-aaf80cb03ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--in IN_CSV] [--out OUT_CSV] [--text SINGLE_TEXT] [--print]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\sagni\\AppData\\Roaming\\jupyter\\runtime\\kernel-c8cc4447-445e-4194-a3ca-7019d0ade62a.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    }
   ],
   "source": [
    "# === predict_ecohabit.py ===\n",
    "# Jupyter/Terminal safe predictor for EcoHabit model\n",
    "# Uses artifacts from: C:\\Users\\sagni\\Downloads\\Eco Habit\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "OUT_DIR = r\"C:\\Users\\sagni\\Downloads\\Eco Habit\"\n",
    "PKL_PATH = os.path.join(OUT_DIR, \"mindpal_preprocess.pkl\")\n",
    "H5_PATH  = os.path.join(OUT_DIR, \"mindpal_model.h5\")\n",
    "DEFAULT_OUT = os.path.join(OUT_DIR, \"predictions.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# Helper classes (for joblib)\n",
    "# -----------------------------\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column): self.column = column\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X): return X[[self.column]]\n",
    "\n",
    "class To1DString(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return X.iloc[:, 0].astype(str).values\n",
    "        return np.asarray(X).astype(str).ravel()\n",
    "\n",
    "class DateTimeExpand(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns): self.columns = columns\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        outs = []\n",
    "        for c in self.columns:\n",
    "            s = pd.to_datetime(X[c], errors=\"coerce\")\n",
    "            outs.append(pd.DataFrame({\n",
    "                f\"{c}_year\":  s.dt.year.fillna(0).astype(int),\n",
    "                f\"{c}_month\": s.dt.month.fillna(0).astype(int),\n",
    "                f\"{c}_day\":   s.dt.day.fillna(0).astype(int),\n",
    "                f\"{c}_dow\":   s.dt.dayofweek.fillna(0).astype(int),\n",
    "            }))\n",
    "        return pd.concat(outs, axis=1) if outs else np.empty((len(X), 0))\n",
    "\n",
    "# -----------------------------\n",
    "# Utility\n",
    "# -----------------------------\n",
    "def ensure_dense_if_small(X, max_feats=50000):\n",
    "    if hasattr(X, \"toarray\") and X.shape[1] <= max_feats:\n",
    "        return X.toarray()\n",
    "    return X\n",
    "\n",
    "def compile_loaded_model(model, n_classes: int):\n",
    "    if n_classes <= 2:\n",
    "        model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    else:\n",
    "        model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "def build_df_for_text(text: str, bundle: dict):\n",
    "    \"\"\"Build a 1-row DataFrame for single-text prediction\"\"\"\n",
    "    df_dict = {}\n",
    "    # Fill numeric with 0, categorical with \"unknown\", datetime with today, text with input\n",
    "    for c in bundle[\"numeric_cols\"]: df_dict[c] = [0]\n",
    "    for c in bundle[\"cat_cols\"]: df_dict[c] = [\"unknown\"]\n",
    "    for c in bundle[\"datetime_cols\"]: df_dict[c] = [pd.Timestamp.today()]\n",
    "    for c in bundle[\"text_cols\"]: df_dict[c] = [text]\n",
    "    return pd.DataFrame(df_dict)\n",
    "\n",
    "# -----------------------------\n",
    "# Predict function\n",
    "# -----------------------------\n",
    "def predict_dataframe(df_in, bundle, model, out_csv=None, print_out=False):\n",
    "    preprocess = bundle[\"preprocess\"]\n",
    "    X_proc = preprocess.transform(df_in)\n",
    "    X_proc = ensure_dense_if_small(X_proc)\n",
    "\n",
    "    probs = model.predict(X_proc, verbose=0)\n",
    "    n_classes = len(bundle[\"label_encoder\"].classes_)\n",
    "    if n_classes <= 2:\n",
    "        y_pred = (probs.ravel() >= 0.5).astype(int)\n",
    "        preds = bundle[\"label_encoder\"].inverse_transform(y_pred)\n",
    "        df_out = df_in.copy()\n",
    "        df_out[\"pred_label\"] = preds\n",
    "        df_out[\"prob\"] = probs.ravel()\n",
    "    else:\n",
    "        y_pred = np.argmax(probs, axis=1)\n",
    "        preds = bundle[\"label_encoder\"].inverse_transform(y_pred)\n",
    "        df_out = df_in.copy()\n",
    "        df_out[\"pred_label\"] = preds\n",
    "        for i, cls in enumerate(bundle[\"label_encoder\"].classes_):\n",
    "            df_out[f\"prob_{cls}\"] = probs[:, i]\n",
    "\n",
    "    if out_csv:\n",
    "        df_out.to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "    if print_out:\n",
    "        print(df_out[[\"pred_label\"] + [c for c in df_out.columns if c.startswith(\"prob\")]].head())\n",
    "    return df_out\n",
    "\n",
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"EcoHabit Prediction Script\")\n",
    "    parser.add_argument(\"--in\", dest=\"in_csv\", help=\"Path to input CSV (same columns as training)\")\n",
    "    parser.add_argument(\"--out\", dest=\"out_csv\", help=\"Where to save predictions CSV\")\n",
    "    parser.add_argument(\"--text\", dest=\"single_text\", help=\"Single text string for quick prediction\")\n",
    "    parser.add_argument(\"--print\", action=\"store_true\", help=\"Print predictions to console\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Jupyter/IPython arg fix\n",
    "    if \"ipykernel_launcher\" in sys.argv[0]:\n",
    "        sys.argv = [sys.argv[0]]\n",
    "\n",
    "    # Load bundle + model\n",
    "    bundle = joblib.load(PKL_PATH)\n",
    "    model = load_model(H5_PATH)\n",
    "    n_classes = len(bundle[\"label_encoder\"].classes_)\n",
    "    compile_loaded_model(model, n_classes)\n",
    "\n",
    "    if args.single_text:\n",
    "        df_in = build_df_for_text(args.single_text, bundle)\n",
    "    elif args.in_csv:\n",
    "        df_in = pd.read_csv(args.in_csv)\n",
    "    else:\n",
    "        raise ValueError(\"Provide either --text 'some sentence' or --in path\\\\to\\\\file.csv\")\n",
    "\n",
    "    out_csv = args.out_csv or DEFAULT_OUT\n",
    "    predict_dataframe(df_in, bundle, model, out_csv, print_out=args.print)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2883c0-884e-4354-a545-4236423c97fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
